{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "470aff84",
      "metadata": {
        "id": "470aff84"
      },
      "source": [
        "# AmazonReviews2023 ‚Äî Handmade_Products (Filtered) ‚Äî UniSRec + BLAIR\n",
        "\n",
        "This notebook implements a BLAIR-based recommendation pipeline on the Handmade_Products domain of AmazonReviews2023, targeting a sequential / item recommendation task.\n",
        "The dataset has been pre-filtered externally to this domain and is provided as local CSV files.\n",
        "\n",
        "After cloning the repository, the workflow is as follows:\n",
        "\n",
        "Upload the filtered review and metadata CSV files.\n",
        "\n",
        "Create dataset/process_local_csv.py to convert the local CSV data into RecBole-compatible format.\n",
        "\n",
        "Run training and evaluation with RecBole, saving models and metrics.\n",
        "\n",
        "Export all relevant artefacts (processed data, logs, results) for reporting and submission."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc0250ef",
      "metadata": {
        "id": "fc0250ef"
      },
      "source": [
        "## 0. Setup\n",
        "Environment setup and dependency installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "62613a01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62613a01",
        "outputId": "7cf582f9-966a-48ac-8605-2f2528eac27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.19.1\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pyarrow_hotfix\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.70.16)\n",
            "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1)\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.13.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (6.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.19.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.19.1) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.19.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.19.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.19.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.19.1) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.1) (1.17.0)\n",
            "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow_hotfix, fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.19.1 fsspec-2024.3.1 pyarrow_hotfix-0.7\n",
            "Collecting recbole\n",
            "  Downloading recbole-1.2.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from recbole) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.12/dist-packages (from recbole) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from recbole) (1.16.3)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from recbole) (2.2.2)\n",
            "Collecting colorlog==4.7.2 (from recbole)\n",
            "  Downloading colorlog-4.7.2-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting colorama==0.4.4 (from recbole)\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from recbole) (1.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from recbole) (6.0.3)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from recbole) (2.19.0)\n",
            "Collecting thop>=0.1.1.post2207130030 (from recbole)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.12/dist-packages (from recbole) (0.9.0)\n",
            "Requirement already satisfied: plotly>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from recbole) (5.24.1)\n",
            "Collecting texttable>=0.9.0 (from recbole)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.12/dist-packages (from recbole) (5.9.5)\n",
            "INFO: pip is looking at multiple versions of recbole to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting recbole\n",
            "  Downloading recbole-1.2.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->recbole) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->recbole) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->recbole) (2025.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=4.0.0->recbole) (9.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.23.2->recbole) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.23.2->recbole) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.5.0->recbole) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.5.0->recbole) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.5.0->recbole) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.5.0->recbole) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.5.0->recbole) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.5.0->recbole) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.5.0->recbole) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.5.0->recbole) (3.1.4)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->recbole) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->recbole) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->recbole) (3.0.3)\n",
            "Downloading recbole-1.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Downloading colorlog-4.7.2-py2.py3-none-any.whl (10 kB)\n",
            "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: texttable, colorlog, colorama, thop, recbole\n",
            "Successfully installed colorama-0.4.4 colorlog-4.7.2 recbole-1.2.0 texttable-1.7.0 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==2.19.1 pyarrow_hotfix\n",
        "!pip install recbole transformers sentencepiece tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc201576",
      "metadata": {
        "id": "dc201576"
      },
      "source": [
        "## 1. Imports\n",
        "Set up imports, reproducibility seed (if needed), and basic helpers for file checking and result export."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ae09b23c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae09b23c",
        "outputId": "26bddcf1-6615-40d6-ee70-f84ab5ecd86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 2.0.2\n",
            "pyarrow: 18.1.0\n",
            "pandas: 2.2.2\n",
            "datasets: 2.19.1\n",
            "torch: 2.9.0+cu126\n",
            "recbole: 1.2.0\n",
            "RUN_ID = 20251228_063300\n",
            "EXPORT_DIR = exports/20251228_063300\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pyarrow as pa\n",
        "import pandas as pd\n",
        "import datasets\n",
        "import torch\n",
        "import recbole\n",
        "\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"pyarrow:\", pa.__version__)\n",
        "print(\"pandas:\", pd.__version__)\n",
        "print(\"datasets:\", datasets.__version__)\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"recbole:\", recbole.__version__)\n",
        "\n",
        "import os, json, time\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "def now_id():\n",
        "    return datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "RUN_ID = now_id()\n",
        "EXPORT_DIR = f\"exports/{RUN_ID}\"\n",
        "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
        "print('RUN_ID =', RUN_ID)\n",
        "print('EXPORT_DIR =', EXPORT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de4c5884",
      "metadata": {
        "id": "de4c5884"
      },
      "source": [
        "## 2. Project repo layout\n",
        "Clone the AmazonReviews2023 repository and navigate to the seq_rec_results directory for subsequent preprocessing and training steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "88026aff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88026aff",
        "outputId": "7016bc78-8232-4351-8418-aa1a2510b57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'AmazonReviews2023'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 127 (delta 25), reused 20 (delta 20), pack-reused 87 (from 1)\u001b[K\n",
            "Receiving objects: 100% (127/127), 344.61 KiB | 15.66 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n",
            "/content/AmazonReviews2023/seq_rec_results\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!rm -rf AmazonReviews2023\n",
        "\n",
        "!git clone https://github.com/hyp1231/AmazonReviews2023.git\n",
        "%cd /content/AmazonReviews2023/seq_rec_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border-left: 6px solid #d93025; background: #fdecea; padding: 12px 14px; border-radius: 10px;\">\n",
        "  <b>üö® IMPORTANT</b>\n",
        "  <ul style=\"margin: 8px 0 0 18px;\">\n",
        "    <li><b>Upload</b> the filtered review (/content/AmazonReviews2023/seq_rec_results/local_data/review_filtered.csv) and metadata CSV (/content/AmazonReviews2023/seq_rec_results/local_data/metadata.csv) files.</li>\n",
        "    <li><b>Create</b> <code>dataset/process_local_csv.py</code> to convert the local CSV data into <b>RecBole-compatible format</b>.</li>\n",
        "  </ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "4XGK9ez6TEi-"
      },
      "id": "4XGK9ez6TEi-"
    },
    {
      "cell_type": "markdown",
      "id": "6e0f854c",
      "metadata": {
        "id": "6e0f854c"
      },
      "source": [
        "## 3. Train‚ÄìValidation‚ÄìTest Split\n",
        "As the data is already filtered before being loaded into the notebook, we split it into training, validation, and test sets following an 8:1:1 ratio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data sanity check"
      ],
      "metadata": {
        "id": "j5ebVnmfCkp8"
      },
      "id": "j5ebVnmfCkp8"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7f773a80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7f773a80",
        "outputId": "adf3ee1f-9c78-4191-aee4-18a43a87c6f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        user_id        asin parent_asin  rating  \\\n",
              "0  AFZUK3MTBIBEDQOPAK3OATUOUKLA  B07PWBRXJG  B07PWBRXJG     5.0   \n",
              "1  AFZUK3MTBIBEDQOPAK3OATUOUKLA  B0855GMD9K  B0855GMD9K     5.0   \n",
              "2  AFZUK3MTBIBEDQOPAK3OATUOUKLA  B07HN8PP1V  B07HN8PP1V     5.0   \n",
              "3  AFZUK3MTBIBEDQOPAK3OATUOUKLA  B07PVC79VH  B07PVC79VH     5.0   \n",
              "4  AFZUK3MTBIBEDQOPAK3OATUOUKLA  B07T947ZG1  B07T947ZG1     5.0   \n",
              "\n",
              "                                  title  \\\n",
              "0                   fair trade necklace   \n",
              "1         Set of 2 Fair Trade bracelets   \n",
              "2     Green Fair Trade African bracelet   \n",
              "3  Recycled fair trade African bracelet   \n",
              "4          African fair trade bracelets   \n",
              "\n",
              "                                                text  helpful_vote  \\\n",
              "0  This is a very lovely, fair trade necklace mad...             1   \n",
              "1  I purchased about 5 different color combos of ...             7   \n",
              "2  I purchased about 5 different color combos of ...             2   \n",
              "3  Very lovely, VERY easy to take on and off beca...             1   \n",
              "4  I purchased about 5 different color combos of ...             2   \n",
              "\n",
              "   verified_purchase            timestamp  \n",
              "0               True  2020-12-05 19:21:29  \n",
              "1               True  2020-12-04 19:15:16  \n",
              "2               True  2020-12-04 19:14:01  \n",
              "3               True  2020-12-04 19:11:46  \n",
              "4               True  2020-12-04 19:09:30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80961f40-4a65-4dc3-971a-6989412642a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>asin</th>\n",
              "      <th>parent_asin</th>\n",
              "      <th>rating</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>helpful_vote</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
              "      <td>B07PWBRXJG</td>\n",
              "      <td>B07PWBRXJG</td>\n",
              "      <td>5.0</td>\n",
              "      <td>fair trade necklace</td>\n",
              "      <td>This is a very lovely, fair trade necklace mad...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-12-05 19:21:29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
              "      <td>B0855GMD9K</td>\n",
              "      <td>B0855GMD9K</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Set of 2 Fair Trade bracelets</td>\n",
              "      <td>I purchased about 5 different color combos of ...</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-12-04 19:15:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
              "      <td>B07HN8PP1V</td>\n",
              "      <td>B07HN8PP1V</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Green Fair Trade African bracelet</td>\n",
              "      <td>I purchased about 5 different color combos of ...</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-12-04 19:14:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
              "      <td>B07PVC79VH</td>\n",
              "      <td>B07PVC79VH</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Recycled fair trade African bracelet</td>\n",
              "      <td>Very lovely, VERY easy to take on and off beca...</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-12-04 19:11:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AFZUK3MTBIBEDQOPAK3OATUOUKLA</td>\n",
              "      <td>B07T947ZG1</td>\n",
              "      <td>B07T947ZG1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>African fair trade bracelets</td>\n",
              "      <td>I purchased about 5 different color combos of ...</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-12-04 19:09:30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80961f40-4a65-4dc3-971a-6989412642a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80961f40-4a65-4dc3-971a-6989412642a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80961f40-4a65-4dc3-971a-6989412642a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fade487e-fd3b-43f8-9963-03ed20dfb5e9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fade487e-fd3b-43f8-9963-03ed20dfb5e9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fade487e-fd3b-43f8-9963-03ed20dfb5e9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(df_r[rating_col]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AFZUK3MTBIBEDQOPAK3OATUOUKLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asin\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"B0855GMD9K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_asin\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"B0855GMD9K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Set of 2 Fair Trade bracelets\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I purchased about 5 different color combos of these bracelets and they are GLORIOUS.  One of the main things for me is an easy on and off - with a big bang appearance.  These are perfect.  I really like that this is a fair trade item as well.  They are just so satisfying and so beautiful. And the price?? They are a STEAL.  (Helpful hint:  look for the \\\"sets\\\" - even a better price!)  Honestly, I highly recommend them - try one.  You'll be back.  In fact, I'm going to give a few a gifts.  They come in brown paper wrapped boxes that are actually gift ready.  Pop into a small holiday bag, or even just wrap with a ribbon.  It does say what it is on the outside of the box, but honestly, I'm good with that!  There is a card inside that tells what it is and even an example of how they make the item.  These are coil bracelets, that are not a new look - but these are simply beautifully done in rich, sometimes bright colors and quality made.  I can't say enough positive about them.  Love!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"helpful_vote\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"verified_purchase\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2020-12-04 19:15:16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  main_category                                              title  \\\n",
              "0      Handmade  Daisy Keychain Wristlet Gray Fabric Key fob La...   \n",
              "1      Handmade  Anemone Jewelry Beauteous November Birthstone ...   \n",
              "2      Handmade      Silver Triangle Earrings with Chevron Pattern   \n",
              "3      Handmade  Las Vegas Subway Sign Print - Caesar's, Freemo...   \n",
              "4      Handmade  Round Cut Cubic Zirconia Stud Earrings Fashion...   \n",
              "\n",
              "   average_rating  rating_number  \\\n",
              "0             4.5             12   \n",
              "1             4.1             10   \n",
              "2             5.0              1   \n",
              "3             1.0              1   \n",
              "4             4.2              2   \n",
              "\n",
              "                                            features  \\\n",
              "0  ['High Quality Fabrics', 'Antique Brass Metall...   \n",
              "1  ['Stunning gemstone and detailed design', 'Ban...   \n",
              "2                                                 []   \n",
              "3                                                 []   \n",
              "4  ['‚≠ê„ÄêSize„ÄëThe remarkable cubic zirconia studs h...   \n",
              "\n",
              "                                         description  price  \\\n",
              "0  ['This charming Daisy Fabric Keychain wristlet...    NaN   \n",
              "1  ['Anemone brings this November birthstone ring...  69.00   \n",
              "2  ['These large silver triangles are stamped wit...    NaN   \n",
              "3  [\"Subway Signs make fabulous wall art. A bit o...  19.95   \n",
              "4                                                 []  14.99   \n",
              "\n",
              "                                              images videos  \\\n",
              "0  [{'thumb': 'https://m.media-amazon.com/images/...     []   \n",
              "1  [{'thumb': 'https://m.media-amazon.com/images/...     []   \n",
              "2  [{'thumb': 'https://m.media-amazon.com/images/...     []   \n",
              "3  [{'thumb': 'https://m.media-amazon.com/images/...     []   \n",
              "4  [{'thumb': 'https://m.media-amazon.com/images/...     []   \n",
              "\n",
              "                store                                         categories  \\\n",
              "0             Generic  ['Handmade Products', 'Clothing, Shoes & Acces...   \n",
              "1     Anemone Jewelry  ['Handmade Products', 'Jewelry', 'Rings', 'Sta...   \n",
              "2  Zo√´ Noelle Designs  ['Handmade Products', 'Jewelry', 'Earrings', '...   \n",
              "3             Generic  ['Handmade Products', 'Home & Kitchen', 'Artwo...   \n",
              "4             VDKIDKT  ['Handmade Products', 'Jewelry', 'Earrings', '...   \n",
              "\n",
              "                                             details parent_asin  \\\n",
              "0  {'Package Dimensions': '8 x 4 x 0.85 inches; 0...  B07NTK7T5P   \n",
              "1  {'Department': 'womens', 'Date First Available...  B0751M85FV   \n",
              "2  {'Department': 'Women', 'Date First Available'...  B01HYNE114   \n",
              "3          {'Date First Available': 'June 14, 2018'}  B07TKZF3Z1   \n",
              "4  {'Package Dimensions': '2.36 x 2.05 x 1.65 inc...  B0BKBJT5MM   \n",
              "\n",
              "   bought_together  \n",
              "0              NaN  \n",
              "1              NaN  \n",
              "2              NaN  \n",
              "3              NaN  \n",
              "4              NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef2346d6-97ed-457a-bd57-577ac0b8367a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>main_category</th>\n",
              "      <th>title</th>\n",
              "      <th>average_rating</th>\n",
              "      <th>rating_number</th>\n",
              "      <th>features</th>\n",
              "      <th>description</th>\n",
              "      <th>price</th>\n",
              "      <th>images</th>\n",
              "      <th>videos</th>\n",
              "      <th>store</th>\n",
              "      <th>categories</th>\n",
              "      <th>details</th>\n",
              "      <th>parent_asin</th>\n",
              "      <th>bought_together</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Handmade</td>\n",
              "      <td>Daisy Keychain Wristlet Gray Fabric Key fob La...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>12</td>\n",
              "      <td>['High Quality Fabrics', 'Antique Brass Metall...</td>\n",
              "      <td>['This charming Daisy Fabric Keychain wristlet...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'thumb': 'https://m.media-amazon.com/images/...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Generic</td>\n",
              "      <td>['Handmade Products', 'Clothing, Shoes &amp; Acces...</td>\n",
              "      <td>{'Package Dimensions': '8 x 4 x 0.85 inches; 0...</td>\n",
              "      <td>B07NTK7T5P</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Handmade</td>\n",
              "      <td>Anemone Jewelry Beauteous November Birthstone ...</td>\n",
              "      <td>4.1</td>\n",
              "      <td>10</td>\n",
              "      <td>['Stunning gemstone and detailed design', 'Ban...</td>\n",
              "      <td>['Anemone brings this November birthstone ring...</td>\n",
              "      <td>69.00</td>\n",
              "      <td>[{'thumb': 'https://m.media-amazon.com/images/...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Anemone Jewelry</td>\n",
              "      <td>['Handmade Products', 'Jewelry', 'Rings', 'Sta...</td>\n",
              "      <td>{'Department': 'womens', 'Date First Available...</td>\n",
              "      <td>B0751M85FV</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Handmade</td>\n",
              "      <td>Silver Triangle Earrings with Chevron Pattern</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>['These large silver triangles are stamped wit...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'thumb': 'https://m.media-amazon.com/images/...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Zo√´ Noelle Designs</td>\n",
              "      <td>['Handmade Products', 'Jewelry', 'Earrings', '...</td>\n",
              "      <td>{'Department': 'Women', 'Date First Available'...</td>\n",
              "      <td>B01HYNE114</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Handmade</td>\n",
              "      <td>Las Vegas Subway Sign Print - Caesar's, Freemo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>[\"Subway Signs make fabulous wall art. A bit o...</td>\n",
              "      <td>19.95</td>\n",
              "      <td>[{'thumb': 'https://m.media-amazon.com/images/...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Generic</td>\n",
              "      <td>['Handmade Products', 'Home &amp; Kitchen', 'Artwo...</td>\n",
              "      <td>{'Date First Available': 'June 14, 2018'}</td>\n",
              "      <td>B07TKZF3Z1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Handmade</td>\n",
              "      <td>Round Cut Cubic Zirconia Stud Earrings Fashion...</td>\n",
              "      <td>4.2</td>\n",
              "      <td>2</td>\n",
              "      <td>['‚≠ê„ÄêSize„ÄëThe remarkable cubic zirconia studs h...</td>\n",
              "      <td>[]</td>\n",
              "      <td>14.99</td>\n",
              "      <td>[{'thumb': 'https://m.media-amazon.com/images/...</td>\n",
              "      <td>[]</td>\n",
              "      <td>VDKIDKT</td>\n",
              "      <td>['Handmade Products', 'Jewelry', 'Earrings', '...</td>\n",
              "      <td>{'Package Dimensions': '2.36 x 2.05 x 1.65 inc...</td>\n",
              "      <td>B0BKBJT5MM</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef2346d6-97ed-457a-bd57-577ac0b8367a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef2346d6-97ed-457a-bd57-577ac0b8367a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef2346d6-97ed-457a-bd57-577ac0b8367a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0a34048c-f603-48d9-97a1-244fd8d4b99c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a34048c-f603-48d9-97a1-244fd8d4b99c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0a34048c-f603-48d9-97a1-244fd8d4b99c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(df_r[rating_col]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"main_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Handmade\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Anemone Jewelry Beauteous November Birthstone Ring - Citrine Ring in 14k Gold-filled Band Sizes 3-12.5 - Handcrafted Citrine Jewelry for Women for Any Occasion - Free Jewelry Box\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"average_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5820872289478858,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"features\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"['Stunning gemstone and detailed design', 'Bands are customizable, with metals to choose from', 'Engraving available', 'Nickel Free and Tarnish Resistant', 'Free gift box']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['Anemone brings this November birthstone ring that showcases elegance and style. This November birthstone jewelry features a beautiful faceted Citrine gemstone set in a 14k gold-filled double band, customizable to solid gold and 925 Sterling silver. You will surely love to wear this Citrine ring to formal events and even as everyday jewelry or a gift to November ladies. The perfect classy highlight piece.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.85404551033801,\n        \"min\": 14.99,\n        \"max\": 69.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          69.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"images\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[{'thumb': 'https://m.media-amazon.com/images/I/31C2XBkQFTS._SS40_.jpg', 'large': 'https://m.media-amazon.com/images/I/31C2XBkQFTS.jpg', 'variant': 'MAIN', 'hi_res': 'https://m.media-amazon.com/images/I/71PTBqCt5GS._SL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/41r77nl2RIS._SS40_.jpg', 'large': 'https://m.media-amazon.com/images/I/41r77nl2RIS.jpg', 'variant': 'PT01', 'hi_res': 'https://m.media-amazon.com/images/I/91E7-S9hZmS._SL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/319ny7M8GrS._SS40_.jpg', 'large': 'https://m.media-amazon.com/images/I/319ny7M8GrS.jpg', 'variant': 'PT02', 'hi_res': 'https://m.media-amazon.com/images/I/71yoTdkzALS._SL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/31yNw8W8DdS._SS40_.jpg', 'large': 'https://m.media-amazon.com/images/I/31yNw8W8DdS.jpg', 'variant': 'PT03', 'hi_res': 'https://m.media-amazon.com/images/I/71wYvMH6CyS._SL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/31OTPrnv5DS._SS40_.jpg', 'large': 'https://m.media-amazon.com/images/I/31OTPrnv5DS.jpg', 'variant': 'PT04', 'hi_res': 'https://m.media-amazon.com/images/I/71vasevirsS._SL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/318pd1FZMpS._SS40_.jpg', 'large': 'https://m.media-amazon.com/images/I/318pd1FZMpS.jpg', 'variant': 'PT05', 'hi_res': 'https://m.media-amazon.com/images/I/71qiHAavLaS._SL1500_.jpg'}, {'thumb': 'https://m.media-amazon.com/images/I/51pEwhx0BmL._SS40_.jpg', 'large': 'https://m.media-amazon.com/images/I/51pEwhx0BmL.jpg', 'variant': 'PT06', 'hi_res': None}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"videos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"store\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Anemone Jewelry\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['Handmade Products', 'Jewelry', 'Rings', 'Statement']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"details\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"{'Department': 'womens', 'Date First Available': 'July 30, 2017'}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_asin\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"B0751M85FV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bought_together\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reviews shape : (32510, 9)\n",
            "meta shape    : (164817, 14)\n",
            "n_users: 11180\n",
            "n_items: 15810\n",
            "user interactions (min/median/max): 1 3.0 30\n",
            "item interactions (min/median/max): 1 1.0 60\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rating\n",
              "1.0     1110\n",
              "2.0      662\n",
              "3.0     1224\n",
              "4.0     2350\n",
              "5.0    27164\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>1224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>2350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>27164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# You are currently in: /content/AmazonReviews2023/seq_rec_results\n",
        "BASE = Path(\".\").resolve()\n",
        "\n",
        "REVIEW_CSV = str(BASE / \"local_data\" / \"review_filtered.csv\")\n",
        "META_CSV   = str(BASE / \"local_data\" / \"metadata.csv\")\n",
        "\n",
        "assert os.path.exists(REVIEW_CSV), f\"Missing: {REVIEW_CSV}\"\n",
        "assert os.path.exists(META_CSV),   f\"Missing: {META_CSV}\"\n",
        "\n",
        "df_r = pd.read_csv(REVIEW_CSV)\n",
        "df_m = pd.read_csv(META_CSV)\n",
        "\n",
        "display(df_r.head())\n",
        "display(df_m.head())\n",
        "\n",
        "print(\"reviews shape :\", df_r.shape)\n",
        "print(\"meta shape    :\", df_m.shape)\n",
        "\n",
        "# best-effort columns\n",
        "uid_col = \"user_id\" if \"user_id\" in df_r.columns else None\n",
        "item_col = \"parent_asin\" if \"parent_asin\" in df_r.columns else (\"asin\" if \"asin\" in df_r.columns else None)\n",
        "rating_col = \"rating\" if \"rating\" in df_r.columns else None\n",
        "\n",
        "if uid_col and item_col:\n",
        "    print(\"n_users:\", df_r[uid_col].nunique())\n",
        "    print(\"n_items:\", df_r[item_col].nunique())\n",
        "    # interactions per user/item\n",
        "    u_cnt = df_r.groupby(uid_col)[item_col].size()\n",
        "    i_cnt = df_r.groupby(item_col)[uid_col].size()\n",
        "    print(\"user interactions (min/median/max):\", int(u_cnt.min()), float(u_cnt.median()), int(u_cnt.max()))\n",
        "    print(\"item interactions (min/median/max):\", int(i_cnt.min()), float(i_cnt.median()), int(i_cnt.max()))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Could not infer user/item columns automatically. Please check df_r.columns:\", list(df_r.columns))\n",
        "\n",
        "if rating_col:\n",
        "    display(df_r[rating_col].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train-validation-test split"
      ],
      "metadata": {
        "id": "SGj6i1AAC5Pd"
      },
      "id": "SGj6i1AAC5Pd"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ====== EDIT THESE ======\n",
        "INPUT_CSV = \"/content/AmazonReviews2023/seq_rec_results/local_data/review_filtered.csv\"   # <-- s·ª≠a ƒë∆∞·ªùng d·∫´n\n",
        "OUT_DIR   = \"dataset/processed/Handmade_Products_local/_raw_time_split_8_1_1\"  # <-- s·ª≠a n·∫øu mu·ªën\n",
        "# ========================\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "\n",
        "# ch·ªâ s·∫Øp x·∫øp theo th·ªùi gian (ƒë·ªÉ ƒë√∫ng temporal split)\n",
        "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"timestamp\"])\n",
        "df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "\n",
        "n = len(df)\n",
        "n_train = int(n * 0.8)\n",
        "n_valid = int(n * 0.1)\n",
        "\n",
        "train_df = df.iloc[:n_train].copy()\n",
        "valid_df = df.iloc[n_train:n_train + n_valid].copy()\n",
        "test_df  = df.iloc[n_train + n_valid:].copy()\n",
        "\n",
        "train_path = os.path.join(OUT_DIR, \"train.csv\")\n",
        "valid_path = os.path.join(OUT_DIR, \"valid.csv\")\n",
        "test_path  = os.path.join(OUT_DIR, \"test.csv\")\n",
        "\n",
        "train_df.to_csv(train_path, index=False)\n",
        "valid_df.to_csv(valid_path, index=False)\n",
        "test_df.to_csv(test_path, index=False)\n",
        "\n",
        "print(\"[DONE] temporal split 8/1/1\")\n",
        "print(\"rows:\", n, \"| train:\", len(train_df), \"| valid:\", len(valid_df), \"| test:\", len(test_df))\n",
        "print(\"saved:\", train_path, valid_path, test_path, sep=\"\\n- \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpWujElAyN-o",
        "outputId": "2d6df64d-d587-442a-a93f-76a7f139690c"
      },
      "id": "OpWujElAyN-o",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DONE] temporal split 8/1/1\n",
            "rows: 32510 | train: 26008 | valid: 3251 | test: 3251\n",
            "saved:\n",
            "- dataset/processed/Handmade_Products_local/_raw_time_split_8_1_1/train.csv\n",
            "- dataset/processed/Handmade_Products_local/_raw_time_split_8_1_1/valid.csv\n",
            "- dataset/processed/Handmade_Products_local/_raw_time_split_8_1_1/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd76a67",
      "metadata": {
        "id": "ebd76a67"
      },
      "source": [
        "## 4. Build RecBole dataset\n",
        "Write the script dataset/process_local_csv.py (keeping its content identical to dataset/process_amazon_2023.py), then run it to generate:\n",
        "\n",
        "*.train/valid/test.inter\n",
        "\n",
        "*.item and *.data_maps\n",
        "\n",
        "*.feature (PLM embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "31650f3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31650f3c",
        "outputId": "7fd73074-bf40-4b1b-d3cf-685395120cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 900/900 [07:01<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE FULL PREPROCESS + FEATURE\n",
            "OUT: /content/AmazonReviews2023/seq_rec_results/dataset/processed/Handmade_Products_local\n",
            "train samples: 16278\n",
            "valid samples: 1607\n",
            "test  samples: 1749\n",
            "#Users: 9398\n",
            "#Items: 14388\n",
            "feature: /content/AmazonReviews2023/seq_rec_results/dataset/processed/Handmade_Products_local/Handmade_Products_local.blair-roberta-base.feature\n",
            "avg meta char len: 1105.6536697247707\n"
          ]
        }
      ],
      "source": [
        "import os, re, html, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# ================== CONFIG ==================\n",
        "DOMAIN = \"Handmade_Products_local\"\n",
        "\n",
        "SPLIT_DIR = \"/content/AmazonReviews2023/seq_rec_results/dataset/processed/Handmade_Products_local/_raw_time_split_8_1_1\"\n",
        "TRAIN_CSV = os.path.join(SPLIT_DIR, \"train.csv\")\n",
        "VALID_CSV = os.path.join(SPLIT_DIR, \"valid.csv\")\n",
        "TEST_CSV  = os.path.join(SPLIT_DIR, \"test.csv\")\n",
        "\n",
        "META_CSV = \"/content/AmazonReviews2023/seq_rec_results/local_data/metadata.csv\"\n",
        "\n",
        "OUT_DIR = \"/content/AmazonReviews2023/seq_rec_results/dataset/processed/Handmade_Products_local\"\n",
        "MAX_HIS_LEN = 50\n",
        "\n",
        "PLM = \"hyp1231/blair-roberta-base\"\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16\n",
        "# ===========================================\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# --------- helpers (gi·ªëng tinh th·∫ßn All_Beauty) ---------\n",
        "def list_to_str(x):\n",
        "    if isinstance(x, list):\n",
        "        return list_to_str(\", \".join(x))\n",
        "    return x\n",
        "\n",
        "def clean_text(raw_text):\n",
        "    text = list_to_str(raw_text)\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = html.unescape(str(text)).strip()\n",
        "    text = re.sub(r\"<[^>]+>\", \"\", text)\n",
        "    text = re.sub(r\"[\\n\\t]\", \" \", text)\n",
        "    text = re.sub(r\" +\", \" \", text)\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def feature_process(feature):\n",
        "    # h·ª£p v·ªõi metadata local: float/list/str/NaN\n",
        "    if pd.isna(feature):\n",
        "        return \"\"\n",
        "    if isinstance(feature, float):\n",
        "        return f\"{feature}. \"\n",
        "    if isinstance(feature, list) and len(feature) > 0:\n",
        "        s = \"\"\n",
        "        for v in feature:\n",
        "            s += clean_text(v) + \", \"\n",
        "        return s[:-2] + \". \"\n",
        "    return clean_text(feature) + \". \"\n",
        "\n",
        "def build_item2meta(meta_df):\n",
        "    features_needed = [\"title\", \"features\", \"categories\", \"description\"]\n",
        "    item2meta = {}\n",
        "    for _, row in meta_df.iterrows():\n",
        "        pid = row[\"parent_asin\"]\n",
        "        meta_text = \"\"\n",
        "        for f in features_needed:\n",
        "            meta_text += feature_process(row.get(f, \"\"))\n",
        "        item2meta[pid] = meta_text\n",
        "    return item2meta\n",
        "\n",
        "def truncate_history_str(hist_str, max_his_len):\n",
        "    parts = str(hist_str).split(\" \")\n",
        "    parts = [p for p in parts if p]\n",
        "    return \" \".join(parts[-max_his_len:])\n",
        "\n",
        "def filter_df_by_metadata(df, item2meta):\n",
        "    # drop target kh√¥ng c√≥ metadata\n",
        "    df = df[df[\"parent_asin\"].isin(item2meta)].copy()\n",
        "\n",
        "    # l·ªçc history item kh√¥ng c√≥ metadata\n",
        "    def _filt_hist(h):\n",
        "        items = str(h).split(\" \")\n",
        "        items = [it for it in items if it in item2meta]\n",
        "        return \" \".join(items)\n",
        "\n",
        "    df[\"history\"] = df[\"history\"].apply(_filt_hist)\n",
        "    df = df[df[\"history\"].str.len() > 0].copy()\n",
        "    return df\n",
        "\n",
        "def remap_id(datasets):\n",
        "    user2id = {\"[PAD]\": 0}\n",
        "    id2user = [\"[PAD]\"]\n",
        "    item2id = {\"[PAD]\": 0}\n",
        "    id2item = [\"[PAD]\"]\n",
        "\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        df = datasets[split]\n",
        "        for u, tgt, hist in zip(df[\"user_id\"], df[\"parent_asin\"], df[\"history\"]):\n",
        "            if u not in user2id:\n",
        "                user2id[u] = len(id2user)\n",
        "                id2user.append(u)\n",
        "            if tgt not in item2id:\n",
        "                item2id[tgt] = len(id2item)\n",
        "                id2item.append(tgt)\n",
        "            for it in str(hist).split(\" \"):\n",
        "                if it and it not in item2id:\n",
        "                    item2id[it] = len(id2item)\n",
        "                    id2item.append(it)\n",
        "\n",
        "    return {\"user2id\": user2id, \"id2user\": id2user, \"item2id\": item2id, \"id2item\": id2item}\n",
        "\n",
        "def build_samples_from_interactions(df_inter):\n",
        "    # df_inter: user_id, parent_asin, timestamp\n",
        "    df_inter = df_inter.copy()\n",
        "    df_inter[\"timestamp\"] = pd.to_datetime(df_inter[\"timestamp\"], errors=\"coerce\")\n",
        "    df_inter = df_inter.dropna(subset=[\"timestamp\"])\n",
        "    df_inter = df_inter.sort_values([\"user_id\", \"timestamp\"])\n",
        "\n",
        "    rows = []\n",
        "    for u, g in df_inter.groupby(\"user_id\"):\n",
        "        seq = g[\"parent_asin\"].tolist()\n",
        "        if len(seq) < 2:\n",
        "            continue\n",
        "        for i in range(1, len(seq)):\n",
        "            hist = \" \".join(seq[:i])\n",
        "            rows.append((u, hist, seq[i]))\n",
        "    return pd.DataFrame(rows, columns=[\"user_id\", \"history\", \"parent_asin\"])\n",
        "\n",
        "# ================== LOAD META ==================\n",
        "meta_df = pd.read_csv(META_CSV)\n",
        "if \"parent_asin\" not in meta_df.columns:\n",
        "    raise ValueError(\"metadata.csv thi·∫øu c·ªôt parent_asin\")\n",
        "\n",
        "item2meta = build_item2meta(meta_df)\n",
        "\n",
        "# ================== LOAD SPLITS (interaction raw) ==================\n",
        "train_i = pd.read_csv(TRAIN_CSV)\n",
        "valid_i = pd.read_csv(VALID_CSV)\n",
        "test_i  = pd.read_csv(TEST_CSV)\n",
        "\n",
        "need_cols = {\"user_id\", \"parent_asin\", \"timestamp\"}\n",
        "for name, df in [(\"train\", train_i), (\"valid\", valid_i), (\"test\", test_i)]:\n",
        "    miss = need_cols - set(df.columns)\n",
        "    if miss:\n",
        "        raise ValueError(f\"{name}.csv thi·∫øu c·ªôt {miss}. Ph·∫£i l√† interaction raw.\")\n",
        "\n",
        "# ================== BUILD samples per split ==================\n",
        "datasets = {\n",
        "    \"train\": build_samples_from_interactions(train_i),\n",
        "    \"valid\": build_samples_from_interactions(valid_i),\n",
        "    \"test\":  build_samples_from_interactions(test_i),\n",
        "}\n",
        "\n",
        "# ================== FILTER + TRUNCATE ==================\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    df = datasets[split]\n",
        "    df = filter_df_by_metadata(df, item2meta)\n",
        "    df[\"history\"] = df[\"history\"].apply(lambda h: truncate_history_str(h, MAX_HIS_LEN))\n",
        "    df = df[df[\"history\"].str.len() > 0].copy()\n",
        "    datasets[split] = df.reset_index(drop=True)\n",
        "\n",
        "# ================== WRITE .inter ==================\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    out_path = os.path.join(OUT_DIR, f\"{DOMAIN}.{split}.inter\")\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"user_id:token\\titem_id_list:token_seq\\titem_id:token\\n\")\n",
        "        for u, hist, tgt in zip(datasets[split][\"user_id\"], datasets[split][\"history\"], datasets[split][\"parent_asin\"]):\n",
        "            f.write(f\"{u}\\t{hist}\\t{tgt}\\n\")\n",
        "\n",
        "# ================== DATA MAPS + id2meta ==================\n",
        "data_maps = remap_id(datasets)\n",
        "\n",
        "id2meta = {0: \"[PAD]\"}\n",
        "for asin, meta_text in item2meta.items():\n",
        "    if asin not in data_maps[\"item2id\"]:\n",
        "        continue\n",
        "    item_id = data_maps[\"item2id\"][asin]\n",
        "    id2meta[item_id] = meta_text\n",
        "data_maps[\"id2meta\"] = id2meta\n",
        "\n",
        "with open(os.path.join(OUT_DIR, f\"{DOMAIN}.data_maps\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data_maps, f)\n",
        "\n",
        "# ================== GENERATE ITEM FEATURES (.feature) ==================\n",
        "device = torch.device(DEVICE)\n",
        "tokenizer = AutoTokenizer.from_pretrained(PLM)\n",
        "model = AutoModel.from_pretrained(PLM).to(device)\n",
        "model.eval()\n",
        "\n",
        "# 1-base: sorted_text[0] -> item_id=1\n",
        "sorted_text = [data_maps[\"id2meta\"].get(i, \"\") for i in range(1, len(data_maps[\"item2id\"]))]\n",
        "\n",
        "all_embeddings = []\n",
        "for i in tqdm(range(0, len(sorted_text), BATCH_SIZE)):\n",
        "    batch = sorted_text[i:i + BATCH_SIZE]\n",
        "    inputs = tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    all_embeddings.append(outputs.last_hidden_state[:, 0, :].cpu().numpy())\n",
        "\n",
        "all_embeddings = np.concatenate(all_embeddings, axis=0).astype(np.float32)\n",
        "feature_path = os.path.join(OUT_DIR, f\"{DOMAIN}.{PLM.split('/')[-1]}.feature\")\n",
        "all_embeddings.tofile(feature_path)\n",
        "\n",
        "# ================== STATS ==================\n",
        "print(\"DONE FULL PREPROCESS + FEATURE\")\n",
        "print(\"OUT:\", OUT_DIR)\n",
        "print(\"train samples:\", len(datasets[\"train\"]))\n",
        "print(\"valid samples:\", len(datasets[\"valid\"]))\n",
        "print(\"test  samples:\", len(datasets[\"test\"]))\n",
        "print(\"#Users:\", len(data_maps[\"user2id\"]) - 1)\n",
        "print(\"#Items:\", len(data_maps[\"item2id\"]) - 1)\n",
        "print(\"feature:\", feature_path)\n",
        "print(\"avg meta char len:\", float(np.mean([len(x) for x in sorted_text])) if len(sorted_text) else 0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5239493c",
      "metadata": {
        "id": "5239493c"
      },
      "source": [
        "## 5. Training / Evaluation (UniSRec)\n",
        "**Notebook uses a patched run.py with:**\n",
        "\n",
        "NumPy 2.x compatibility fixes\n",
        "\n",
        "safe torch.load handling\n",
        "\n",
        "automatic PLM embedding attachment (*.feature) during dataset loading\n",
        "\n",
        "**After execution, it produces:**\n",
        "\n",
        "training/evaluation logs\n",
        "\n",
        "resolved config snapshots\n",
        "\n",
        "model checkpoints, all saved under saved/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2feefc1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2feefc1e",
        "outputId": "76484c98-afab-4770-c890-16e102427712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run_with_user_pred.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile run_with_user_pred.py\n",
        "# ==== NumPy 2.0 compatibility patch for older RecBole ====\n",
        "import numpy as np\n",
        "\n",
        "# scalar-type aliases removed/changed in NumPy 2.0\n",
        "if not hasattr(np, \"float_\"):\n",
        "    np.float_ = np.float64\n",
        "if not hasattr(np, \"complex_\"):\n",
        "    np.complex_ = np.complex128\n",
        "if not hasattr(np, \"unicode_\"):\n",
        "    # NumPy 2.0: use str_ instead\n",
        "    np.unicode_ = np.str_\n",
        "if not hasattr(np, \"bool_\"):\n",
        "    np.bool_ = np.bool8\n",
        "if not hasattr(np, \"int_\"):\n",
        "    np.int_ = np.int64\n",
        "\n",
        "# deprecated short names that older libs assign/use\n",
        "if not hasattr(np, \"float\"):\n",
        "    np.float = float\n",
        "if not hasattr(np, \"complex\"):\n",
        "    np.complex = complex\n",
        "if not hasattr(np, \"unicode\"):\n",
        "    np.unicode = str\n",
        "if not hasattr(np, \"bool\"):\n",
        "    np.bool = bool\n",
        "if not hasattr(np, \"int\"):\n",
        "    np.int = int\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "from logging import getLogger\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from recbole.config import Config\n",
        "from recbole.data import data_preparation\n",
        "from recbole.utils import init_seed, init_logger, set_color, get_trainer\n",
        "\n",
        "from utils import get_model, create_dataset\n",
        "\n",
        "# ==== PyTorch 2.6 compatibility patch for RecBole checkpoint loading ====\n",
        "import inspect\n",
        "\n",
        "_torch_load_orig = torch.load\n",
        "def _torch_load_compat(*args, **kwargs):\n",
        "    # If torch.load supports weights_only (PyTorch >=2.6), force it to False unless user specified\n",
        "    if \"weights_only\" in inspect.signature(_torch_load_orig).parameters and \"weights_only\" not in kwargs:\n",
        "        kwargs[\"weights_only\"] = False\n",
        "    return _torch_load_orig(*args, **kwargs)\n",
        "\n",
        "torch.load = _torch_load_compat\n",
        "# =========================================================================\n",
        "\n",
        "\n",
        "def _ndcg_at_k(rec_list, gt_set, k: int) -> float:\n",
        "    k = min(k, len(rec_list))\n",
        "    if k <= 0:\n",
        "        return 0.0\n",
        "    if not gt_set:\n",
        "        return 0.0\n",
        "\n",
        "    dcg = 0.0\n",
        "    for i in range(k):\n",
        "        if rec_list[i] in gt_set:\n",
        "            dcg += 1.0 / math.log2(i + 2)\n",
        "\n",
        "    ideal_hits = min(len(gt_set), k)\n",
        "    idcg = 0.0\n",
        "    for i in range(ideal_hits):\n",
        "        idcg += 1.0 / math.log2(i + 2)\n",
        "\n",
        "    return float(dcg / idcg) if idcg > 0 else 0.0\n",
        "\n",
        "\n",
        "def _id2token_safe(dataset, field, ids):\n",
        "    \"\"\"\n",
        "    Always return:\n",
        "    - if ids is list/tuple/ndarray -> list[str]\n",
        "    - if ids is scalar -> str\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    def _to_list_str(x):\n",
        "        # x can be list/tuple/np.ndarray/torch tensor\n",
        "        if isinstance(x, np.ndarray):\n",
        "            x = x.tolist()\n",
        "        if isinstance(x, torch.Tensor):\n",
        "            x = x.detach().cpu().tolist()\n",
        "        # now x should be list/tuple\n",
        "        return [str(t) for t in list(x)]\n",
        "\n",
        "    # list-like ids -> list[str]\n",
        "    if isinstance(ids, (list, tuple, np.ndarray, torch.Tensor)):\n",
        "        tokens = dataset.id2token(field, list(ids) if not isinstance(ids, torch.Tensor) else ids.detach().cpu().tolist())\n",
        "        return _to_list_str(tokens)\n",
        "\n",
        "    # scalar -> str\n",
        "    tokens = dataset.id2token(field, [ids])\n",
        "    if isinstance(tokens, np.ndarray):\n",
        "        tokens = tokens.tolist()\n",
        "    return str(tokens[0])\n",
        "\n",
        "\n",
        "def save_user_evaluation_details(trainer, test_data, config: Config, out_csv_path: str, ks=(10, 50)):\n",
        "    \"\"\"\n",
        "    Export ƒë√∫ng format nh∆∞ user_evaluation_details.csv:\n",
        "    userID, recommended_items, groundtruth_items, recall@10, precision@10, ndcg@10, recall@50, precision@50, ndcg@50\n",
        "    \"\"\"\n",
        "    logger = getLogger()\n",
        "    device = config[\"device\"]\n",
        "    model = trainer.model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    dataset = test_data.dataset\n",
        "    uid_field = dataset.uid_field\n",
        "    iid_field = dataset.iid_field\n",
        "\n",
        "    # field l·ªãch s·ª≠ ƒë·ªÉ mask items ƒë√£ t∆∞∆°ng t√°c (n·∫øu c√≥)\n",
        "    item_list_field = config[\"ITEM_LIST_FIELD\"] if \"ITEM_LIST_FIELD\" in config else \"item_id_list\"\n",
        "\n",
        "    max_k = max(ks)\n",
        "\n",
        "    # per-user\n",
        "    user2_recs = {}                  # uid(int) -> list[item_id(int)] top-max_k (l·∫•y 1 l·∫ßn)\n",
        "    user2_gt_items = defaultdict(list)  # uid(int) -> list[item_id(int)] (gom l·∫°i)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_data:\n",
        "            # RecBole Sequential dataloader th∆∞·ªùng batch l√† tuple: (interaction, ..., positive_u, positive_i)\n",
        "            interaction = batch[0].to(device)\n",
        "            positive_u = batch[2].to(device)\n",
        "            positive_i = batch[3].to(device)\n",
        "\n",
        "            scores = model.full_sort_predict(interaction)\n",
        "\n",
        "            # mask PAD item id=0\n",
        "            if scores.dim() == 2 and scores.size(1) > 0:\n",
        "                scores[:, 0] = -1e12\n",
        "\n",
        "            # mask history items n·∫øu c√≥\n",
        "            if item_list_field in interaction:\n",
        "                hist = interaction[item_list_field].long()  # [B, L]\n",
        "                B, L = hist.shape\n",
        "                flat_hist = hist.view(-1)\n",
        "                flat_row = torch.arange(B, device=device).unsqueeze(1).expand(B, L).reshape(-1)\n",
        "                mask_ok = flat_hist > 0\n",
        "                scores[flat_row[mask_ok], flat_hist[mask_ok]] = -1e12\n",
        "\n",
        "            topk_items = torch.topk(scores, k=max_k, dim=1).indices  # [B, max_k]\n",
        "\n",
        "            u_list = positive_u.detach().cpu().tolist()\n",
        "            gt_list = positive_i.detach().cpu().tolist()\n",
        "            recs_list = topk_items.detach().cpu().tolist()\n",
        "\n",
        "            for u_id, gt_id, rec_ids in zip(u_list, gt_list, recs_list):\n",
        "                u_id = int(u_id)\n",
        "                gt_id = int(gt_id)\n",
        "                if u_id == 0:\n",
        "                    continue\n",
        "\n",
        "                # store recs once per user (first time seen)\n",
        "                if u_id not in user2_recs:\n",
        "                    user2_recs[u_id] = rec_ids\n",
        "\n",
        "                user2_gt_items[u_id].append(gt_id)\n",
        "\n",
        "    # Build rows\n",
        "    rows = []\n",
        "    for u_id, rec_ids in user2_recs.items():\n",
        "        gt_ids = user2_gt_items.get(u_id, [])\n",
        "\n",
        "        # unique GT gi·ªØ th·ª© t·ª±\n",
        "        seen = set()\n",
        "        gt_unique = []\n",
        "        for x in gt_ids:\n",
        "            if x not in seen:\n",
        "                seen.add(x)\n",
        "                gt_unique.append(x)\n",
        "\n",
        "        user_token = _id2token_safe(dataset, uid_field, u_id)\n",
        "        rec_tokens = _id2token_safe(dataset, iid_field, rec_ids)\n",
        "        gt_tokens = _id2token_safe(dataset, iid_field, gt_unique)\n",
        "        if not isinstance(rec_tokens, (list, tuple)):\n",
        "            rec_tokens = [str(rec_tokens)]\n",
        "        else:\n",
        "            rec_tokens = [str(x) for x in rec_tokens]\n",
        "\n",
        "        if not isinstance(gt_tokens, (list, tuple)):\n",
        "            gt_tokens = [str(gt_tokens)]\n",
        "        else:\n",
        "            gt_tokens = [str(x) for x in gt_tokens]\n",
        "\n",
        "        # normalize list type\n",
        "        if not isinstance(rec_tokens, (list, tuple)):\n",
        "            rec_tokens = [rec_tokens]\n",
        "        if not isinstance(gt_tokens, (list, tuple)):\n",
        "            gt_tokens = [gt_tokens]\n",
        "\n",
        "        gt_set = set(gt_tokens)\n",
        "\n",
        "        row = {\n",
        "            \"userID\": user_token,\n",
        "            \"recommended_items\": \",\".join(rec_tokens),\n",
        "            \"groundtruth_items\": \",\".join(gt_tokens),\n",
        "        }\n",
        "\n",
        "        for k in ks:\n",
        "            rec_k = rec_tokens[:k]\n",
        "            hits = sum(1 for x in rec_k if x in gt_set)\n",
        "            denom_gt = len(gt_set)\n",
        "\n",
        "            row[f\"recall@{k}\"] = float(hits / denom_gt) if denom_gt > 0 else 0.0\n",
        "            row[f\"precision@{k}\"] = float(hits / k) if k > 0 else 0.0\n",
        "            row[f\"ndcg@{k}\"] = _ndcg_at_k(rec_tokens, gt_set, k)\n",
        "\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # fixed column order\n",
        "    ordered_cols = [\"userID\", \"recommended_items\", \"groundtruth_items\"]\n",
        "    for k in ks:\n",
        "        ordered_cols += [f\"recall@{k}\", f\"precision@{k}\", f\"ndcg@{k}\"]\n",
        "    df = df[ordered_cols]\n",
        "\n",
        "    os.makedirs(os.path.dirname(out_csv_path) or \".\", exist_ok=True)\n",
        "    df.to_csv(out_csv_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    logger.info(set_color(\"[SAVED user evaluation details]\", \"green\") + f\" -> {out_csv_path}\")\n",
        "    logger.info(set_color(\"Columns\", \"yellow\") + f\": {list(df.columns)}\")\n",
        "    logger.info(set_color(\"Rows\", \"yellow\") + f\": {len(df)}\")\n",
        "\n",
        "    # optional overall mean dict (m·ªói metric 1 s·ªë)\n",
        "    overall = {c: float(df[c].mean()) for c in df.columns if \"@\" in c}\n",
        "    logger.info(set_color(\"[OVERALL mean metrics]\", \"cyan\") + f\": {overall}\")\n",
        "\n",
        "\n",
        "def run_single(model_name, dataset_name, pretrained_file='', save_user_csv=True, **kwargs):\n",
        "    props = ['config/overall.yaml', f'config/{model_name}.yaml']\n",
        "    print(props)\n",
        "\n",
        "    model_class = get_model(model_name)\n",
        "\n",
        "    config = Config(\n",
        "        model=model_class,\n",
        "        dataset=dataset_name,\n",
        "        config_file_list=props,\n",
        "        config_dict=kwargs\n",
        "    )\n",
        "\n",
        "    init_seed(config['seed'], config['reproducibility'])\n",
        "    init_logger(config)\n",
        "    logger = getLogger()\n",
        "    logger.info(config)\n",
        "\n",
        "    dataset = create_dataset(config)\n",
        "    logger.info(dataset)\n",
        "\n",
        "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
        "\n",
        "    model = model_class(config, train_data.dataset).to(config['device'])\n",
        "\n",
        "    if pretrained_file != '':\n",
        "        checkpoint = torch.load(pretrained_file, map_location=config['device'])\n",
        "        logger.info(f'Loading from {pretrained_file}')\n",
        "        model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
        "\n",
        "    logger.info(model)\n",
        "\n",
        "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
        "\n",
        "    best_valid_score, best_valid_result = trainer.fit(\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        saved=True,\n",
        "        show_progress=config['show_progress']\n",
        "    )\n",
        "\n",
        "    test_result = trainer.evaluate(\n",
        "        test_data,\n",
        "        load_best_model=True,\n",
        "        show_progress=config['show_progress']\n",
        "    )\n",
        "\n",
        "    logger.info(set_color('best valid ', 'yellow') + f': {best_valid_result}')\n",
        "    logger.info(set_color('test result', 'yellow') + f': {test_result}')\n",
        "\n",
        "    # === NEW: xu·∫•t ƒë√∫ng format nh∆∞ user_evaluation_details.csv ===\n",
        "    if save_user_csv:\n",
        "        out_dir = os.path.join(config['checkpoint_dir'], \"per_user_outputs\")\n",
        "        out_csv = os.path.join(out_dir, f\"{dataset_name}__{model_name}__user_evaluation_details.csv\")\n",
        "        save_user_evaluation_details(trainer, test_data, config, out_csv, ks=(10, 50))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-m', type=str, default='UniSRec')\n",
        "    parser.add_argument('-d', type=str, default='Handmade_Products_local')\n",
        "    parser.add_argument('-p', type=str, default='')\n",
        "    parser.add_argument('--no_user_csv', action='store_true')\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "    print(args)\n",
        "\n",
        "    run_single(\n",
        "        args.m,\n",
        "        args.d,\n",
        "        pretrained_file=args.p,\n",
        "        save_user_csv=(not args.no_user_csv)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f7c908",
      "metadata": {
        "id": "e0f7c908"
      },
      "source": [
        "### Run training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "9eff10a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eff10a1",
        "outputId": "253b40f8-058d-4f56-da2c-e218ad5598ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-28 08:19:43.455702: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766909983.491995   28106 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766909983.502880   28106 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766909983.525908   28106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766909983.525944   28106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766909983.525952   28106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766909983.525958   28106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Namespace(m='UniSRec', d='Handmade_Products_local', p='', no_user_csv=False)\n",
            "['config/overall.yaml', 'config/UniSRec.yaml']\n",
            "command line args [-m UniSRec -d Handmade_Products_local] will not be used in RecBole\n",
            "28 Dec 08:19    INFO  \n",
            "\u001b[1;35mGeneral Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
            "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 2020\u001b[0m\n",
            "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
            "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m dataset/processed/Handmade_Products_local\u001b[0m\n",
            "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m saved\u001b[0m\n",
            "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m False\u001b[0m\n",
            "\n",
            "\u001b[1;35mTraining Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 300\u001b[0m\n",
            "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
            "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
            "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.001\u001b[0m\n",
            "\u001b[1;36mtrain_neg_sample_args\u001b[0m =\u001b[1;33m {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\u001b[0m\n",
            "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 1\u001b[0m\n",
            "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
            "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
            "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
            "\n",
            "\u001b[1;35mEvaluation Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\u001b[0m\n",
            "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['Recall', 'NDCG']\u001b[0m\n",
            "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10, 50]\u001b[0m\n",
            "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m NDCG@10\u001b[0m\n",
            "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
            "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
            "\n",
            "\u001b[1;35mDataset Hyper Parameters:\n",
            "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
            "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
            "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
            "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m item_id\u001b[0m\n",
            "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
            "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
            "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
            "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
            "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'item_id_list', 'item_id']}\u001b[0m\n",
            "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
            "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m [0,inf)\u001b[0m\n",
            "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m [0,inf)\u001b[0m\n",
            "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m ['item_id_list']\u001b[0m\n",
            "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m None\u001b[0m\n",
            "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
            "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
            "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
            "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
            "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
            "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
            "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
            "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
            "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m ['train', 'valid', 'test']\u001b[0m\n",
            "\n",
            "\u001b[1;35mOther Hyper Parameters: \n",
            "\u001b[0m\u001b[1;36mworker\u001b[0m = \u001b[1;33m0\u001b[0m\n",
            "\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
            "\u001b[1;36mshuffle\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
            "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36menable_amp\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36menable_scaler\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36mtransform\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
            "\u001b[1;36mnumerical_features\u001b[0m = \u001b[1;33m[]\u001b[0m\n",
            "\u001b[1;36mdiscretization\u001b[0m = \u001b[1;33mNone\u001b[0m\n",
            "\u001b[1;36mkg_reverse_r\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
            "\u001b[1;36mentity_kg_num_interval\u001b[0m = \u001b[1;33m[0,inf)\u001b[0m\n",
            "\u001b[1;36mrelation_kg_num_interval\u001b[0m = \u001b[1;33m[0,inf)\u001b[0m\n",
            "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.SEQUENTIAL\u001b[0m\n",
            "\u001b[1;36mn_layers\u001b[0m = \u001b[1;33m2\u001b[0m\n",
            "\u001b[1;36mn_heads\u001b[0m = \u001b[1;33m2\u001b[0m\n",
            "\u001b[1;36mhidden_size\u001b[0m = \u001b[1;33m300\u001b[0m\n",
            "\u001b[1;36minner_size\u001b[0m = \u001b[1;33m256\u001b[0m\n",
            "\u001b[1;36mhidden_dropout_prob\u001b[0m = \u001b[1;33m0.5\u001b[0m\n",
            "\u001b[1;36mattn_dropout_prob\u001b[0m = \u001b[1;33m0.5\u001b[0m\n",
            "\u001b[1;36mhidden_act\u001b[0m = \u001b[1;33mgelu\u001b[0m\n",
            "\u001b[1;36mlayer_norm_eps\u001b[0m = \u001b[1;33m1e-12\u001b[0m\n",
            "\u001b[1;36minitializer_range\u001b[0m = \u001b[1;33m0.02\u001b[0m\n",
            "\u001b[1;36mloss_type\u001b[0m = \u001b[1;33mCE\u001b[0m\n",
            "\u001b[1;36mitem_drop_ratio\u001b[0m = \u001b[1;33m0.2\u001b[0m\n",
            "\u001b[1;36mitem_drop_coefficient\u001b[0m = \u001b[1;33m0.9\u001b[0m\n",
            "\u001b[1;36mlambda\u001b[0m = \u001b[1;33m0.001\u001b[0m\n",
            "\u001b[1;36mplm_suffix\u001b[0m = \u001b[1;33mblair-roberta-base.feature\u001b[0m\n",
            "\u001b[1;36mtrain_stage\u001b[0m = \u001b[1;33minductive_ft\u001b[0m\n",
            "\u001b[1;36mplm_size\u001b[0m = \u001b[1;33m768\u001b[0m\n",
            "\u001b[1;36madaptor_dropout_prob\u001b[0m = \u001b[1;33m0.2\u001b[0m\n",
            "\u001b[1;36madaptor_layers\u001b[0m = \u001b[1;33m[768, 300]\u001b[0m\n",
            "\u001b[1;36mtemperature\u001b[0m = \u001b[1;33m0.07\u001b[0m\n",
            "\u001b[1;36mn_exps\u001b[0m = \u001b[1;33m8\u001b[0m\n",
            "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.POINTWISE\u001b[0m\n",
            "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
            "\u001b[1;36msingle_spec\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
            "\u001b[1;36mlocal_rank\u001b[0m = \u001b[1;33m0\u001b[0m\n",
            "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
            "\u001b[1;36mvalid_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
            "\u001b[1;36mtest_neg_sample_args\u001b[0m = \u001b[1;33m{'distribution': 'uniform', 'sample_num': 'none'}\u001b[0m\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[0m/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[field].fillna(value=\"\", inplace=True)\n",
            "\u001b[0m/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[field].fillna(value=\"\", inplace=True)\n",
            "\u001b[0m/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:501: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[field].fillna(value=\"\", inplace=True)\n",
            "\u001b[0m/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:1217: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
            "  split_point = np.cumsum(feat[field].agg(len))[:-1]\n",
            "\u001b[0m/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  feat[field].fillna(value=0, inplace=True)\n",
            "\u001b[0m/usr/local/lib/python3.12/dist-packages/recbole/data/dataset/sequential_dataset.py:165: FutureWarning: using <built-in function len> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
            "  ].agg(len)\n",
            "\u001b[0m28 Dec 08:19    INFO  \u001b[1;35mHandmade_Products_local\u001b[0m\n",
            "\u001b[1;34mThe number of users\u001b[0m: 9399\n",
            "\u001b[1;34mAverage actions of users\u001b[0m: 2.0891679080655456\n",
            "\u001b[1;34mThe number of items\u001b[0m: 14389\n",
            "\u001b[1;34mAverage actions of items\u001b[0m: 1.8140996026979581\n",
            "\u001b[1;34mThe number of inters\u001b[0m: 19634\n",
            "\u001b[1;34mThe sparsity of the dataset\u001b[0m: 99.98548234323084%\n",
            "\u001b[1;34mRemain Fields\u001b[0m: ['user_id', 'item_id_list', 'item_id', 'item_length']\u001b[0m\n",
            "\u001b[0m28 Dec 08:19    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
            "\u001b[0m28 Dec 08:19    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[2048]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\u001b[0m\n",
            "\u001b[0m28 Dec 08:19    INFO  UniSRec(\n",
            "  (item_embedding): None\n",
            "  (position_embedding): Embedding(50, 300)\n",
            "  (trm_encoder): TransformerEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-1): 2 x TransformerLayer(\n",
            "        (multi_head_attention): MultiHeadAttention(\n",
            "          (query): Linear(in_features=300, out_features=300, bias=True)\n",
            "          (key): Linear(in_features=300, out_features=300, bias=True)\n",
            "          (value): Linear(in_features=300, out_features=300, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
            "          (dense): Linear(in_features=300, out_features=300, bias=True)\n",
            "          (LayerNorm): LayerNorm((300,), eps=1e-12, elementwise_affine=True)\n",
            "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (dense_1): Linear(in_features=300, out_features=256, bias=True)\n",
            "          (dense_2): Linear(in_features=256, out_features=300, bias=True)\n",
            "          (LayerNorm): LayerNorm((300,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (LayerNorm): LayerNorm((300,), eps=1e-12, elementwise_affine=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (loss_fct): CrossEntropyLoss()\n",
            "  (plm_embedding): Embedding(14389, 768, padding_idx=0)\n",
            "  (moe_adaptor): MoEAdaptorLayer(\n",
            "    (experts): ModuleList(\n",
            "      (0-7): 8 x PWLayer(\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (lin): Linear(in_features=768, out_features=300, bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\u001b[1;34m\n",
            "Trainable parameters\u001b[0m: 2910344\u001b[0m\n",
            "\u001b[1;35mTrain     0\u001b[0m:   0%|                                                            | 0/8 [00:00<?, ?it/s]\u001b[0m\u001b[0m/usr/local/lib/python3.12/dist-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
            "\u001b[1;35mTrain     0\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.86it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:19    INFO  \u001b[1;32mepoch 0 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 4.30s, \u001b[1;34mtrain loss\u001b[0m: 66.0800]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.73it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:19    INFO  \u001b[1;32mepoch 0 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.19s, \u001b[1;34mvalid_score\u001b[0m: 0.161600]\u001b[0m\n",
            "\u001b[0m28 Dec 08:19    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.211    recall@50 : 0.3018    ndcg@10 : 0.1616    ndcg@50 : 0.182\u001b[0m\n",
            "\u001b[0m28 Dec 08:19    INFO  \u001b[1;34mSaving current\u001b[0m: saved/UniSRec-Dec-28-2025_08-19-50.pth\u001b[0m\n",
            "\u001b[1;35mTrain     1\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.01it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 1 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.98s, \u001b[1;34mtrain loss\u001b[0m: 59.4519]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.35it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 1 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mvalid_score\u001b[0m: 0.171900]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2234    recall@50 : 0.3093    ndcg@10 : 0.1719    ndcg@50 : 0.1908\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mSaving current\u001b[0m: saved/UniSRec-Dec-28-2025_08-19-50.pth\u001b[0m\n",
            "\u001b[1;35mTrain     2\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.01it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 2 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.98s, \u001b[1;34mtrain loss\u001b[0m: 57.3005]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.07it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 2 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mvalid_score\u001b[0m: 0.173800]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2284    recall@50 : 0.3205    ndcg@10 : 0.1738    ndcg@50 : 0.194\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mSaving current\u001b[0m: saved/UniSRec-Dec-28-2025_08-19-50.pth\u001b[0m\n",
            "\u001b[1;35mTrain     3\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.99it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 3 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 4.01s, \u001b[1;34mtrain loss\u001b[0m: 56.0537]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.03it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 3 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.15s, \u001b[1;34mvalid_score\u001b[0m: 0.178100]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2346    recall@50 : 0.3205    ndcg@10 : 0.1781    ndcg@50 : 0.1971\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mSaving current\u001b[0m: saved/UniSRec-Dec-28-2025_08-19-50.pth\u001b[0m\n",
            "\u001b[1;35mTrain     4\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.98it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 4 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 4.05s, \u001b[1;34mtrain loss\u001b[0m: 54.9841]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.49it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 4 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mvalid_score\u001b[0m: 0.176600]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2309    recall@50 : 0.3267    ndcg@10 : 0.1766    ndcg@50 : 0.1976\u001b[0m\n",
            "\u001b[1;35mTrain     5\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.03it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 5 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.94s, \u001b[1;34mtrain loss\u001b[0m: 54.3162]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.76it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 5 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.178600]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2352    recall@50 : 0.3335    ndcg@10 : 0.1786    ndcg@50 : 0.2\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mSaving current\u001b[0m: saved/UniSRec-Dec-28-2025_08-19-50.pth\u001b[0m\n",
            "\u001b[1;35mTrain     6\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.05it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 6 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.90s, \u001b[1;34mtrain loss\u001b[0m: 53.6761]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.97it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 6 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.176500]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2309    recall@50 : 0.3261    ndcg@10 : 0.1765    ndcg@50 : 0.1978\u001b[0m\n",
            "\u001b[1;35mTrain     7\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.09it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 7 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.83s, \u001b[1;34mtrain loss\u001b[0m: 53.2056]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.85it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 7 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.177400]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2327    recall@50 : 0.3311    ndcg@10 : 0.1774    ndcg@50 : 0.1987\u001b[0m\n",
            "\u001b[1;35mTrain     8\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.09it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 8 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.83s, \u001b[1;34mtrain loss\u001b[0m: 52.8335]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.76it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 8 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mvalid_score\u001b[0m: 0.177400]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2315    recall@50 : 0.3317    ndcg@10 : 0.1774    ndcg@50 : 0.1994\u001b[0m\n",
            "\u001b[1;35mTrain     9\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.10it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 9 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.82s, \u001b[1;34mtrain loss\u001b[0m: 52.3967]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.98it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 9 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.178900]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2346    recall@50 : 0.3279    ndcg@10 : 0.1789    ndcg@50 : 0.1994\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mSaving current\u001b[0m: saved/UniSRec-Dec-28-2025_08-19-50.pth\u001b[0m\n",
            "\u001b[1;35mTrain    10\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.13it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 10 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.76s, \u001b[1;34mtrain loss\u001b[0m: 52.1219]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.20it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 10 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.177700]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.234    recall@50 : 0.3329    ndcg@10 : 0.1777    ndcg@50 : 0.199\u001b[0m\n",
            "\u001b[1;35mTrain    11\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.07it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 11 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.86s, \u001b[1;34mtrain loss\u001b[0m: 51.7492]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.16it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 11 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.179500]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2365    recall@50 : 0.3323    ndcg@10 : 0.1795    ndcg@50 : 0.2003\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mSaving current\u001b[0m: saved/UniSRec-Dec-28-2025_08-19-50.pth\u001b[0m\n",
            "\u001b[1;35mTrain    12\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.03it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 12 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.95s, \u001b[1;34mtrain loss\u001b[0m: 51.4441]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.32it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 12 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.179100]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2352    recall@50 : 0.3329    ndcg@10 : 0.1791    ndcg@50 : 0.2008\u001b[0m\n",
            "\u001b[1;35mTrain    13\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.08it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 13 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.85s, \u001b[1;34mtrain loss\u001b[0m: 51.1791]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.24it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 13 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.177600]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2321    recall@50 : 0.3348    ndcg@10 : 0.1776    ndcg@50 : 0.1999\u001b[0m\n",
            "\u001b[1;35mTrain    14\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.15it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 14 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.73s, \u001b[1;34mtrain loss\u001b[0m: 50.7878]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.04it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 14 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.177100]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2315    recall@50 : 0.3342    ndcg@10 : 0.1771    ndcg@50 : 0.1997\u001b[0m\n",
            "\u001b[1;35mTrain    15\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.12it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 15 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.77s, \u001b[1;34mtrain loss\u001b[0m: 50.5554]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.96it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;32mepoch 15 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.176400]\u001b[0m\n",
            "\u001b[0m28 Dec 08:20    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2296    recall@50 : 0.3335    ndcg@10 : 0.1764    ndcg@50 : 0.1992\u001b[0m\n",
            "\u001b[1;35mTrain    16\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.11it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 16 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.80s, \u001b[1;34mtrain loss\u001b[0m: 50.2653]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.90it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 16 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.176800]\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2327    recall@50 : 0.3354    ndcg@10 : 0.1768    ndcg@50 : 0.1993\u001b[0m\n",
            "\u001b[1;35mTrain    17\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.12it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 17 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.77s, \u001b[1;34mtrain loss\u001b[0m: 49.9342]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.87it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 17 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.176900]\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2296    recall@50 : 0.3317    ndcg@10 : 0.1769    ndcg@50 : 0.1993\u001b[0m\n",
            "\u001b[1;35mTrain    18\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.62it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 18 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 4.96s, \u001b[1;34mtrain loss\u001b[0m: 49.7145]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.56it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 18 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.19s, \u001b[1;34mvalid_score\u001b[0m: 0.178000]\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2334    recall@50 : 0.3335    ndcg@10 : 0.178    ndcg@50 : 0.1996\u001b[0m\n",
            "\u001b[1;35mTrain    19\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:04<00:00,  1.69it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 19 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 4.73s, \u001b[1;34mtrain loss\u001b[0m: 49.4660]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.80it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 19 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.177200]\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2334    recall@50 : 0.3323    ndcg@10 : 0.1772    ndcg@50 : 0.1988\u001b[0m\n",
            "\u001b[1;35mTrain    20\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.08it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 20 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.85s, \u001b[1;34mtrain loss\u001b[0m: 49.1721]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.70it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 20 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mvalid_score\u001b[0m: 0.174900]\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2284    recall@50 : 0.323    ndcg@10 : 0.1749    ndcg@50 : 0.1957\u001b[0m\n",
            "\u001b[1;35mTrain    21\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.07it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 21 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.86s, \u001b[1;34mtrain loss\u001b[0m: 48.9090]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.92it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 21 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.13s, \u001b[1;34mvalid_score\u001b[0m: 0.176400]\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2315    recall@50 : 0.3298    ndcg@10 : 0.1764    ndcg@50 : 0.1982\u001b[0m\n",
            "\u001b[1;35mTrain    22\u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:03<00:00,  2.08it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 22 training\u001b[0m [\u001b[1;34mtime\u001b[0m: 3.85s, \u001b[1;34mtrain loss\u001b[0m: 48.7070]\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.72it/s, \u001b[1;33mGPU RAM: 4.24 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32mepoch 22 evaluating\u001b[0m [\u001b[1;34mtime\u001b[0m: 0.14s, \u001b[1;34mvalid_score\u001b[0m: 0.176300]\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;34mvalid result\u001b[0m: \n",
            "recall@10 : 0.2302    recall@50 : 0.3329    ndcg@10 : 0.1763    ndcg@50 : 0.1991\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  Finished training, best eval result in epoch 11\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  Loading model structure and parameters from saved/UniSRec-Dec-28-2025_08-19-50.pth\u001b[0m\n",
            "\u001b[1;35mEvaluate   \u001b[0m: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.73it/s, \u001b[1;33mGPU RAM: 4.27 G/14.74 G\u001b[0m]\u001b[0m\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;33mbest valid \u001b[0m: OrderedDict({'recall@10': np.float64(0.2365), 'recall@50': np.float64(0.3323), 'ndcg@10': np.float64(0.1795), 'ndcg@50': np.float64(0.2003)})\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;33mtest result\u001b[0m: OrderedDict({'recall@10': np.float64(0.2619), 'recall@50': np.float64(0.3442), 'ndcg@10': np.float64(0.2204), 'ndcg@50': np.float64(0.2383)})\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;32m[SAVED user evaluation details]\u001b[0m -> saved/per_user_outputs/Handmade_Products_local__UniSRec__user_evaluation_details.csv\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;33mColumns\u001b[0m: ['userID', 'recommended_items', 'groundtruth_items', 'recall@10', 'precision@10', 'ndcg@10', 'recall@50', 'precision@50', 'ndcg@50']\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;33mRows\u001b[0m: 1748\u001b[0m\n",
            "\u001b[0m28 Dec 08:21    INFO  \u001b[1;36m[OVERALL mean metrics]\u001b[0m: {'recall@10': 0.07780320366132723, 'precision@10': 0.007780320366132724, 'ndcg@10': 0.048794560267566324, 'recall@50': 0.15675057208237986, 'precision@50': 0.0031350114416475974, 'ndcg@50': 0.06599580721343788}\u001b[0m\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python run_with_user_pred.py -m UniSRec -d Handmade_Products_local\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28ed3d4",
      "metadata": {
        "id": "a28ed3d4"
      },
      "source": [
        "## 6. Collect results & export\n",
        "The cell below attempts to collect commonly required artifacts for reporting or submission purposes, including:\n",
        "\n",
        "the most recent log file\n",
        "\n",
        "the configuration YAML files\n",
        "\n",
        "the model checkpoint\n",
        "\n",
        "the metrics/result files generated by RecBole\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5ee62083",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ee62083",
        "outputId": "d099c752-8bb5-4400-ec14-575b836bf049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ zipped processed dataset -> exports/20251228_063300/processed_Handmade_Products_local.zip\n",
            "saved files: 6\n",
            "‚úÖ copied 5 saved files into exports/20251228_063300/saved_subset\n",
            "‚úÖ zipped saved_subset -> exports/20251228_063300/saved_subset.zip\n",
            "‚úÖ wrote manifest -> exports/20251228_063300/manifest.json\n"
          ]
        }
      ],
      "source": [
        "import shutil, glob, json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# ===== Required identifiers =====\n",
        "DOMAIN = \"Handmade_Products\"\n",
        "DOMAIN_LOCAL = \"Handmade_Products_local\"   # t√™n dataset trong dataset/processed\n",
        "RUN_ID = RUN_ID  # n·∫øu ƒë√£ c√≥ ·ªü cell tr∆∞·ªõc\n",
        "EXPORT_DIR = EXPORT_DIR  # n·∫øu ƒë√£ c√≥ ·ªü cell tr∆∞·ªõc\n",
        "\n",
        "# ===== Export root =====\n",
        "export_root = Path(EXPORT_DIR)\n",
        "export_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ===== Copy processed dataset =====\n",
        "proc_src = Path(\"dataset/processed\") / DOMAIN_LOCAL\n",
        "if proc_src.exists():\n",
        "    shutil.make_archive(\n",
        "        str(export_root / f\"processed_{DOMAIN_LOCAL}\"),\n",
        "        \"zip\",\n",
        "        root_dir=str(proc_src)\n",
        "    )\n",
        "    print(\"‚úÖ zipped processed dataset ->\", export_root / f\"processed_{DOMAIN_LOCAL}.zip\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è processed dataset dir not found:\", proc_src)\n",
        "\n",
        "# ===== Locate RecBole saved outputs =====\n",
        "saved = Path(\"saved\")\n",
        "if saved.exists():\n",
        "    candidates = [p for p in saved.rglob(\"*\") if p.is_file()]\n",
        "    candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    print(\"saved files:\", len(candidates))\n",
        "\n",
        "    keep_ext = {\".log\", \".txt\", \".yaml\", \".yml\", \".pth\", \".pt\", \".ckpt\", \".json\"}\n",
        "    kept = 0\n",
        "    for p in candidates:\n",
        "        if p.suffix.lower() in keep_ext:\n",
        "            rel = p.relative_to(saved)\n",
        "            dst = export_root / \"saved_subset\" / rel\n",
        "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy2(p, dst)\n",
        "            kept += 1\n",
        "            if kept >= 50:\n",
        "                break\n",
        "\n",
        "    print(f\"‚úÖ copied {kept} saved files into\", export_root / \"saved_subset\")\n",
        "    shutil.make_archive(\n",
        "        str(export_root / \"saved_subset\"),\n",
        "        \"zip\",\n",
        "        root_dir=str(export_root / \"saved_subset\")\n",
        "    )\n",
        "    print(\"‚úÖ zipped saved_subset ->\", export_root / \"saved_subset.zip\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è RecBole saved/ folder not found. Maybe training did not run.\")\n",
        "\n",
        "# ===== Write run manifest =====\n",
        "manifest = {\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"domain\": DOMAIN,\n",
        "    \"dataset_name\": DOMAIN_LOCAL,\n",
        "    \"plm\": PLM_NAME if \"PLM_NAME\" in globals() else None,\n",
        "    \"review_csv\": REVIEW_CSV,\n",
        "    \"meta_csv\": META_CSV,\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "}\n",
        "with open(export_root / \"manifest.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"‚úÖ wrote manifest ->\", export_root / \"manifest.json\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}